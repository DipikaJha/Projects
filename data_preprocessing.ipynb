{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNVw4HLwluCN+e6fwGVioGv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gPJ8TztkxaPF","executionInfo":{"status":"ok","timestamp":1724828347394,"user_tz":-330,"elapsed":775,"user":{"displayName":"dipika jha","userId":"13789347732690819207"}},"outputId":"5b108d96-b122-4879-fac2-7fc2b0887e36"},"outputs":[{"output_type":"stream","name":"stdout","text":["Data merged and columns dropped successfully. The output is saved as 'merged_filtered_data.csv'.\n"]}],"source":["import pandas as pd\n","\n","# Load the sales opensea data and filters data CSV files\n","opensea_data = pd.read_csv('/content/Sales_opensea.csv')  # Replace with your file path\n","filters_data = pd.read_csv('/content/filtered_file.csv')  # Replace with your file path\n","\n","# Merge the data on 'token_id' column\n","merged_data = pd.merge(opensea_data, filters_data, on='token_id')\n","\n","# List of columns to drop\n","columns_to_drop = [\n","    'image_link', 'auction_type', 'sale_price', 'payment_token_symbol', 'decimals',\n","    'eth_price', 'from_account', 'to_account', 'transaction_hash',\n","    'seller_address', 'winner_address', 'listing_time'\n","]\n","\n","# Drop the specified columns\n","final_data = merged_data.drop(columns=columns_to_drop)\n","\n","# Save the final data to a new CSV file\n","final_data.to_csv('merged_filtered_data.csv', index=False)\n","\n","print(\"Data merged and columns dropped successfully. The output is saved as 'merged_filtered_data.csv'.\")"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# Step 1: Load the CSV file (Replace with the path to your CSV file)\n","data = pd.read_csv('/content/merged_filtered_data.csv')  # Update with the correct path\n","\n","# Step 2: Generate dummy sentiment scores for each timeframe\n","np.random.seed(42)  # For reproducibility\n","data['sentiment_1w'] = np.random.uniform(-1, 1, data.shape[0])  # Dummy sentiment score for 1 week\n","data['sentiment_2w'] = np.random.uniform(-1, 1, data.shape[0])  # Dummy sentiment score for 2 weeks\n","data['sentiment_1m'] = np.random.uniform(-1, 1, data.shape[0])  # Dummy sentiment score for 1 month\n","data['sentiment_2m'] = np.random.uniform(-1, 1, data.shape[0])  # Dummy sentiment score for 2 months\n","\n","# Step 3: Save the updated DataFrame to a new CSV file\n","data.to_csv('updated_with_sentiment_scores.csv', index=False)  # Update path as needed\n","\n","print(\"Sentiment scores added successfully. The updated CSV is saved as 'updated_with_sentiment_scores.csv' in your Google Drive.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pNGFo492yFNc","executionInfo":{"status":"ok","timestamp":1724828722692,"user_tz":-330,"elapsed":553,"user":{"displayName":"dipika jha","userId":"13789347732690819207"}},"outputId":"c06f5a5e-9297-4801-8257-f71f47676ba4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentiment scores added successfully. The updated CSV is saved as 'updated_with_sentiment_scores.csv' in your Google Drive.\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Step 1: Load the CSV file (Replace with the path to your CSV file)\n","data = pd.read_csv('/content/updated_with_sentiment_scores.csv')  # Update with the correct path\n","\n","# Step 2: Select the first 50 rows\n","first_50_rows = data.head(50)\n","\n","# Step 3: Save the first 50 rows to a new CSV file\n","first_50_rows.to_csv('first_50_rows_data.csv', index=False)  # Update path as needed\n","\n","print(\"First 50 rows selected and saved as 'first_50_rows_data.csv' in your Google Drive.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iTkL4fWj31yv","executionInfo":{"status":"ok","timestamp":1724829911856,"user_tz":-330,"elapsed":544,"user":{"displayName":"dipika jha","userId":"13789347732690819207"}},"outputId":"f05346ec-f726-4930-c27c-cf24b8f95abc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["First 50 rows selected and saved as 'first_50_rows_data.csv' in your Google Drive.\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Load your Sales OpenSea data\n","sales_opensea_data = pd.read_csv('/content/Sales_opensea.csv')  # Adjust filename as needed\n","\n","# Load your labeled data\n","labeled_data = pd.read_csv('/content/labeled_data_converted.csv')  # Adjust filename as needed\n","\n","# Convert event_timestamp to datetime format to ensure proper merging\n","# Adjust format if the date format is different\n","sales_opensea_data['event_timestamp'] = pd.to_datetime(sales_opensea_data['event_timestamp'])\n","labeled_data['event_timestamp'] = pd.to_datetime(labeled_data['event_timestamp'], format=\"%d-%m-%Y %H:%M\")\n","\n","# Merge eth_price from sales_opensea_data into labeled_data\n","merged_data = pd.merge(\n","    labeled_data,\n","    sales_opensea_data[['token_id', 'event_timestamp', 'eth_price']],\n","    on=['token_id', 'event_timestamp'],\n","    how='left'\n",")\n","\n","# Display the merged data\n","print(merged_data.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5f-B3hML720Z","executionInfo":{"status":"ok","timestamp":1725100858358,"user_tz":-330,"elapsed":508,"user":{"displayName":"dipika jha","userId":"13789347732690819207"}},"outputId":"9f5f4c56-053d-498b-b098-c68fe6533887"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["                                            token_id     event_timestamp  \\\n","0  1157920000000000063387879948516631512075771509... 2019-03-03 22:05:00   \n","1  1157920000000000063387879948516631512075771509... 2019-03-03 22:05:00   \n","2  1157920000000000063387879948516631512075771509... 2020-12-13 07:14:00   \n","3  1157920000000000063387879948516631512075771509... 2019-03-17 01:37:00   \n","4  1157920000000000063387879948516631512075771509... 2020-12-13 04:57:00   \n","\n","   usd_price    x   y  DistanceToDistrict  DistanceToRoad  DistanceToPlaza  \\\n","0   0.396352 -150  23                   4               1               10   \n","1   0.396352 -150  22                   3               1               10   \n","2   0.396352 -150  -5                   0               4               10   \n","3   0.396352 -150  -5                   0               4               10   \n","4   0.396352 -150  -6                   0               5               10   \n","\n","   rarity_score sentiment_1_week_before_category  \\\n","0     695.23066                         Positive   \n","1     691.09593                         Positive   \n","2     736.46458                          Neutral   \n","3     736.46458                         Positive   \n","4     739.45334                          Neutral   \n","\n","  sentiment_2_weeks_before_category sentiment_3_weeks_before_category  \\\n","0                          Positive                          Positive   \n","1                          Positive                          Positive   \n","2                           Neutral                          Positive   \n","3                          Positive                          Positive   \n","4                           Neutral                          Positive   \n","\n","  sentiment_1_month_before_category  eth_price  \n","0                          Positive        NaN  \n","1                          Positive        NaN  \n","2                          Positive        NaN  \n","3                          Positive        NaN  \n","4                          Positive        NaN  \n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Load your Sales OpenSea data\n","sales_opensea_data = pd.read_csv('/content/Sales_opensea.csv')  # Adjust filename as needed\n","\n","# Load your labeled data\n","labeled_data = pd.read_csv('/content/labeled_data_converted.csv')  # Adjust filename as needed\n","\n","sales_opensea_data['event_timestamp'] = pd.to_datetime(sales_opensea_data['event_timestamp'], format='%Y-%m-%d %H:%M:%S')\n","labeled_data['event_timestamp'] = pd.to_datetime(labeled_data['event_timestamp'], format='%d-%m-%Y %H:%M')\n","\n","# Display some unique token_id and event_timestamp values from both datasets\n","print(\"Unique token_id values in sales_opensea_data:\")\n","print(sales_opensea_data['token_id'].unique()[:10])  # Show the first 10 unique token_ids\n","\n","print(\"Unique token_id values in labeled_data:\")\n","print(labeled_data['token_id'].unique()[:10])  # Show the first 10 unique token_ids\n","\n","print(\"Unique event_timestamp values in sales_opensea_data:\")\n","print(sales_opensea_data['event_timestamp'].unique()[:10])  # Show the first 10 unique event_timestamps\n","\n","print(\"Unique event_timestamp values in labeled_data:\")\n","print(labeled_data['event_timestamp'].unique()[:10])  # Show the first 10 unique event_timestamps\n","\n","# Check if there are leading/trailing spaces in token_id\n","sales_opensea_data['token_id'] = sales_opensea_data['token_id'].astype(str).str.strip()\n","labeled_data['token_id'] = labeled_data['token_id'].astype(str).str.strip()\n","\n","# Merge the datasets on token_id and event_timestamp\n","merged_data = pd.merge(labeled_data, sales_opensea_data[['token_id', 'event_timestamp', 'eth_price']],\n","                       on=['token_id', 'event_timestamp'], how='left')\n","\n","# Check if there are any NaN values in eth_price after the merge\n","print(\"Number of NaN eth_price in merged_data:\", merged_data['eth_price'].isna().sum())\n","\n","# Display some rows with NaN eth_price\n","print(\"Rows with missing eth_price:\")\n","print(merged_data[merged_data['eth_price'].isna()].head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TrrFu8MaCMya","executionInfo":{"status":"ok","timestamp":1725101606163,"user_tz":-330,"elapsed":507,"user":{"displayName":"dipika jha","userId":"13789347732690819207"}},"outputId":"f592581f-f39c-4954-8d9c-02a1f1037240"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Unique token_id values in sales_opensea_data:\n","['115792089237316195423570985008687907802227629627499794519951392893147897921559'\n"," '115792089237316195423570985008687907802227629627499794519951392893147897921558'\n"," '115792089237316195423570985008687907802567911994420732983414767500579666132987'\n"," '115792089237316195423570985008687907802567911994420732983414767500579666132986'\n"," '115792089237316195423570985008687907802567911994420732983414767500579666132985'\n"," '115792089237316195423570985008687907802567911994420732983414767500579666132854'\n"," '115792089237316195423570985008687907802567911994420732983414767500579666132853'\n"," '115792089237316195423570985008687907802567911994420732983414767500579666132852'\n"," '115792089237316195423570985008687907802567911994420732983414767500579666132851'\n"," '115792089237316195423570985008687907802567911994420732983414767500579666133004']\n","Unique token_id values in labeled_data:\n","['115792000000000006338787994851663151207577150942036907702027610804647924596736'\n"," '50361800000000003437775313610138212892672'\n"," '50702099999999999426851109115171977560064'\n"," '5444519999999999714220959165680933928960'\n"," '5784799999999999403278900023489623752704'\n"," '6125080000000000301262660495927488282624'\n"," '6465359999999999990320601353736178106368'\n"," '6805650000000000247239108764415754764288'\n"," '7145929999999999936297049622224444588032'\n"," '11569599999999998806557800046979247505408']\n","Unique event_timestamp values in sales_opensea_data:\n","<DatetimeArray>\n","['2019-03-03 22:05:47', '2019-03-03 22:05:13', '2020-12-13 07:14:20',\n"," '2019-03-17 01:37:37', '2020-12-13 04:57:22', '2019-03-14 20:15:25',\n"," '2020-12-13 07:13:42', '2019-03-28 12:33:42', '2018-11-22 03:05:50',\n"," '2018-11-13 16:08:39']\n","Length: 10, dtype: datetime64[ns]\n","Unique event_timestamp values in labeled_data:\n","<DatetimeArray>\n","['2019-03-03 22:05:00', '2020-12-13 07:14:00', '2019-03-17 01:37:00',\n"," '2020-12-13 04:57:00', '2019-03-14 20:15:00', '2020-12-13 07:13:00',\n"," '2019-03-28 12:33:00', '2022-04-22 19:35:00', '2022-01-25 01:08:00',\n"," '2019-02-17 20:13:00']\n","Length: 10, dtype: datetime64[ns]\n","Number of NaN eth_price in merged_data: 5516\n","Rows with missing eth_price:\n","                                            token_id     event_timestamp  \\\n","0  1157920000000000063387879948516631512075771509... 2019-03-03 22:05:00   \n","1  1157920000000000063387879948516631512075771509... 2019-03-03 22:05:00   \n","2  1157920000000000063387879948516631512075771509... 2020-12-13 07:14:00   \n","3  1157920000000000063387879948516631512075771509... 2019-03-17 01:37:00   \n","4  1157920000000000063387879948516631512075771509... 2020-12-13 04:57:00   \n","\n","   usd_price    x   y  DistanceToDistrict  DistanceToRoad  DistanceToPlaza  \\\n","0   0.396352 -150  23                   4               1               10   \n","1   0.396352 -150  22                   3               1               10   \n","2   0.396352 -150  -5                   0               4               10   \n","3   0.396352 -150  -5                   0               4               10   \n","4   0.396352 -150  -6                   0               5               10   \n","\n","   rarity_score sentiment_1_week_before_category  \\\n","0     695.23066                         Positive   \n","1     691.09593                         Positive   \n","2     736.46458                          Neutral   \n","3     736.46458                         Positive   \n","4     739.45334                          Neutral   \n","\n","  sentiment_2_weeks_before_category sentiment_3_weeks_before_category  \\\n","0                          Positive                          Positive   \n","1                          Positive                          Positive   \n","2                           Neutral                          Positive   \n","3                          Positive                          Positive   \n","4                           Neutral                          Positive   \n","\n","  sentiment_1_month_before_category  eth_price  \n","0                          Positive        NaN  \n","1                          Positive        NaN  \n","2                          Positive        NaN  \n","3                          Positive        NaN  \n","4                          Positive        NaN  \n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"NZJz7o0YCM3T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Load your labeled data (replace with your actual file path)\n","labeled_data = pd.read_csv('/content/labeled_combined_file.csv', dtype={'token_id': str})  # Ensure token_id is read as a string\n","\n","# Convert 'token_id' to a full string representation\n","labeled_data['token_id'] = labeled_data['token_id'].apply(lambda x: '{:.0f}'.format(float(x)) if 'E' in x else x)\n","\n","# Display the updated DataFrame to verify changes\n","print(labeled_data.head())\n","\n","labeled_data.to_csv('labeled_data_converted.csv', index=False)\n","\n","print(\"The converted labeled data has been saved to 'labeled_data_full_token_id.csv'.\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C1UMBLqe724Q","executionInfo":{"status":"ok","timestamp":1725100174160,"user_tz":-330,"elapsed":534,"user":{"displayName":"dipika jha","userId":"13789347732690819207"}},"outputId":"16be3bea-dd1c-44cc-97f5-828ae3e95491"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["                                            token_id   event_timestamp  \\\n","0  1157920000000000063387879948516631512075771509...  03-03-2019 22:05   \n","1  1157920000000000063387879948516631512075771509...  03-03-2019 22:05   \n","2  1157920000000000063387879948516631512075771509...  13-12-2020 07:14   \n","3  1157920000000000063387879948516631512075771509...  17-03-2019 01:37   \n","4  1157920000000000063387879948516631512075771509...  13-12-2020 04:57   \n","\n","   usd_price    x   y  DistanceToDistrict  DistanceToRoad  DistanceToPlaza  \\\n","0   0.396352 -150  23                   4               1               10   \n","1   0.396352 -150  22                   3               1               10   \n","2   0.396352 -150  -5                   0               4               10   \n","3   0.396352 -150  -5                   0               4               10   \n","4   0.396352 -150  -6                   0               5               10   \n","\n","   rarity_score sentiment_1_week_before_category  \\\n","0     695.23066                         Positive   \n","1     691.09593                         Positive   \n","2     736.46458                          Neutral   \n","3     736.46458                         Positive   \n","4     739.45334                          Neutral   \n","\n","  sentiment_2_weeks_before_category sentiment_3_weeks_before_category  \\\n","0                          Positive                          Positive   \n","1                          Positive                          Positive   \n","2                           Neutral                          Positive   \n","3                          Positive                          Positive   \n","4                           Neutral                          Positive   \n","\n","  sentiment_1_month_before_category  \n","0                          Positive  \n","1                          Positive  \n","2                          Positive  \n","3                          Positive  \n","4                          Positive  \n","The converted labeled data has been saved to 'labeled_data_full_token_id.csv'.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"VxL-ZZztCJNb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"T2qfEl_CCJUi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7-n5ICFG727g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"03JlHLJL72-x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2asAFqjI73Co"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NCbrWfiX73GA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZDqrAiEZ73Jj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Load your labeled data\n","labeled_data = pd.read_csv('labeled_data.csv')\n","\n","# Load economic data (replace with actual file names for Ether, Bitcoin, Gold, and Crude Oil)\n","ether_data = pd.read_csv('ether_price.csv')\n","bitcoin_data = pd.read_csv('bitcoin_price.csv')\n","gold_data = pd.read_csv('gold_price.csv')\n","crude_oil_data = pd.read_csv('crude_oil_price.csv')\n","\n","# Convert 'Date' and 'event_timestamp' to datetime format for merging\n","labeled_data['event_timestamp'] = pd.to_datetime(labeled_data['event_timestamp'], format='%d-%m-%Y %H:%M')\n","ether_data['Date'] = pd.to_datetime(ether_data['Date'], format='%d-%m-%Y')\n","bitcoin_data['Date'] = pd.to_datetime(bitcoin_data['Date'], format='%d-%m-%Y')\n","gold_data['Date'] = pd.to_datetime(gold_data['Date'], format='%d-%m-%Y')\n","crude_oil_data['Date'] = pd.to_datetime(crude_oil_data['Date'], format='%d-%m-%Y')\n","\n","# Select only the 'Date' and 'Price' columns from each economic data file\n","ether_data = ether_data[['Date', 'Price']].rename(columns={'Price': 'Ether_Price'})\n","bitcoin_data = bitcoin_data[['Date', 'Price']].rename(columns={'Price': 'Bitcoin_Price'})\n","gold_data = gold_data[['Date', 'Price']].rename(columns={'Price': 'Gold_Price'})\n","crude_oil_data = crude_oil_data[['Date', 'Price']].rename(columns={'Price': 'Crude_Oil_Price'})\n","\n","# Merge the labeled data with each economic indicator data on date\n","merged_data = pd.merge_asof(\n","    labeled_data.sort_values('event_timestamp'),\n","    ether_data.sort_values('Date'),\n","    left_on='event_timestamp',\n","    right_on='Date',\n","    direction='nearest'\n",").drop(columns=['Date'])  # Drop redundant 'Date' column after merging\n","\n","merged_data = pd.merge_asof(\n","    merged_data.sort_values('event_timestamp'),\n","    bitcoin_data.sort_values('Date'),\n","    left_on='event_timestamp',\n","    right_on='Date',\n","    direction='nearest'\n",").drop(columns=['Date'])\n","\n","merged_data = pd.merge_asof(\n","    merged_data.sort_values('event_timestamp'),\n","    gold_data.sort_values('Date'),\n","    left_on='event_timestamp',\n","    right_on='Date',\n","    direction='nearest'\n",").drop(columns=['Date'])\n","\n","merged_data = pd.merge_asof(\n","    merged_data.sort_values('event_timestamp'),\n","    crude_oil_data.sort_values('Date'),\n","    left_on='event_timestamp',\n","    right_on='Date',\n","    direction='nearest'\n",").drop(columns=['Date'])\n","\n","# Display merged data\n","print(merged_data.head())\n","\n","# Save the merged data to a CSV file\n","merged_data.to_csv('merged_data_with_prices.csv', index=False)\n"],"metadata":{"id":"e5juj_FE4ip6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Y846rb8J4iuD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5aIxfZtE4ixr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bYJN6dNy4i1K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OVbxD_ap4i4z"},"execution_count":null,"outputs":[]}]}